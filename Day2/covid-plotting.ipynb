{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Data and Panda Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Download and clean a real-world dataset\n",
    "- Use the datetime datatype to resample a time series\n",
    "- Plot different timeframes of a time series\n",
    "- Use the datetime datatype to group data by days of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate the Data\n",
    "- This dataset is from the Center for Systems Science and Engineering at Johns Hopkins University.\n",
    "- This page is a table of links to CSV files; take a look: <https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports>\n",
    "- We begin by harvesting the CSV files names listed on this site and cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the contents of the HTML table from the GitHub Page\n",
    "csv_files = pd.read_html('https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports')[0]\n",
    "csv_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows that don't contain a filename\n",
    "csv_files = csv_files[csv_files['Name'].str.contains('.csv')]\n",
    "csv_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the name column\n",
    "csv_files = list(csv_files['Name'])\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "- We now loop through each CSV file on this page and download a separate CSV file for each day of collected data.\n",
    "- With each iteration, we append the CSV filename to the end of a base URL to get a URL that pooints to that file.\n",
    "- We use `read_csv()` and the file URL to download each CSV file and append the resulting dataframe to the `covid_days` list.\n",
    "- `dtype` explicitly defines the datatype of a column for Pandas.\n",
    "  - `Int64` is a \"smart\" integer type that handles NaN values well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_days = []\n",
    "for day in csv_files:\n",
    "    # Status update\n",
    "    print('Downloading ' + day)\n",
    "    covid_days.append(pd.read_csv(base_url + day,\n",
    "                                  dtype={'Confirmed':'Int64', 'Deaths': 'Int64',\n",
    "                                          'Recovered': 'Int64', 'FIPS': 'Int64', 'Active': 'Int64'}))\n",
    "print('Done downloading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data - create a new column indicating the day\n",
    "- Each day has it's own file named according to the date.\n",
    "- We want to combine all the data into one dataframe.\n",
    "- To distinguish date, we will add a new column called `Day` to each dataframe in our list and populate every entry in that column with the date from the filename.\n",
    "- `enumerate()` provides the item and its index (sometimes we need both in a loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, day in enumerate(csv_files):\n",
    "    covid_days[i]['Day'] = day.strip('.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first day in our dataset\n",
    "covid_days[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data - combine all days into one dataframe\n",
    "- `concat()` combines multiple dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = pd.concat(covid_days, axis=0)\n",
    "# Write the combined raw data to a CSV file for later use\n",
    "covid_data.to_csv('data_raw/covid-days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a peek\n",
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get to know our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many entries do we have?\n",
    "covid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What columns are in our dataset?\n",
    "covid_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data - repeat columns\n",
    "- They added columns as time went on.\n",
    "- When we combined older data with newer data, there were columns that contain the same information.\n",
    "- So long as these columns don't have overlapping entries, we can safely combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are `Country_Region` and `Country/Region` safe to combine -- Yes\n",
    "covid_data[covid_data['Country_Region'].notnull() & covid_data['Country/Region'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge entries from `Country/Region` into `Country_Region`\n",
    "covid_data['Country_Region'] = covid_data['Country_Region'].where(covid_data['Country_Region'].notnull(), covid_data['Country/Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We repeat this process for other similar columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data[covid_data['Last Update'].notnull() & covid_data['Last_Update'].notnull()]\n",
    "covid_data['Last_Update'] = covid_data['Last_Update'].where(covid_data['Last_Update'].notnull(), covid_data['Last Update'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data - finishing touches\n",
    "- We will remove the data we don't need for the purposes of this exercise\n",
    "- Convert the `Day` column to Panda's `datetime` type\n",
    "  - This is a very powerful datatype for time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of unnesessary columns by selecting what we want\n",
    "covid_data = covid_data[['Country_Region', 'Day', 'Confirmed', 'Deaths', 'Recovered', 'Active']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert `Day` to datetime\n",
    "covid_data['Day'] = pd.to_datetime(covid_data['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look\n",
    "covid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datetime and time series\n",
    "- Datetime date types have a lot of hand features\n",
    "- We can find the length of time by subtracting two datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data['Day'].max() - covid_data['Day'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's narrow the data again and look at confirmed cases in three countries that have seen heavy media coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_countries = covid_data[covid_data['Country_Region'].isin(['Mainland China', 'US', 'Italy'])]\n",
    "three_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pivot_table` (like in Excel) is like `pivot`, but it accepts an `aggfunc` parameter that defines how we combine values\n",
    "  - Notice that each country has multiple entries for each date. We will sum the values for each date in the `confirmed` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed = three_countries.pivot_table(index='Day', columns='Country_Region', values='Confirmed', aggfunc='sum')\n",
    "confirmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By setting the column (Day) with the datetime datatype as the index, time series become very convenient. Let's plot a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "time_series = confirmed.dropna(axis='rows')\n",
    "# Plot US confirmed cases\n",
    "time_series['US'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all three countries' confirmed cases\n",
    "time_series.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now datetime comes into its own ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the timeseries up to March 9th\n",
    "time_series[:'2020-03-09'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This shows total cases. Let's look at new cases.\n",
    "- `diff()` computes the difference between two time steps and allows us to understand rates of change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cases = time_series.diff()\n",
    "new_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cases['2020-02-01':'2020-03-10'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can change the granularity of our step.\n",
    "- Let's plot by week instead of day.\n",
    "- `resample()` lets us change the step size and define how we combine values.\n",
    "  - In this case, we look at the max new cases per week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cases['2020-02-01':'2020-03-10'].resample(\"W\").max().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can use datetime to group data by days of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a subset of the data and treat the dates as a normal column instead of an index\n",
    "new_cases = new_cases['2020-02-01':'2020-03-10'].reset_index()\n",
    "new_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the country columns\n",
    "new_cases = new_cases.melt(id_vars='Day')\n",
    "# Fix data types\n",
    "new_cases['value'] = new_cases['value'].astype('Int64')\n",
    "# Split, apply, combine:\n",
    "# Group by day of the week then the country,\n",
    "# finding averages of new cases for each category\n",
    "week_days = new_cases.groupby([new_cases['Day'].dt.weekday, 'Country_Region'])['value'].mean()\n",
    "week_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final plot of mean number of new cases by day and country\n",
    "week_days.plot(kind='bar',figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Download and clean a real-world dataset\n",
    "- Use the datetime datatype to resample a time series\n",
    "- Plot different timeframes of a time series\n",
    "- Use the datetime datatype to group data by days of the week"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
